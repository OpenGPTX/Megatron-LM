{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Data Preprocesser",
            "type": "debugpy",
            "request": "launch",
            "program": "/workspaces/Megatron-LM/tools/preprocess_data.py",
            "console": "integratedTerminal",
            "args": [
                    "--input",
                    "/workspace/dataset/data/sampled_data.jsonl",
                    "--tokenizer-type",
                    "GPT2BPETokenizer",
                    "--output-prefix",
                    "/workspace/dataset/data/preprocessed_samples",
                    "--vocab-file",
                    "/workspace/tokenizer/vocab.json",
                    "--merge-file",
                    "/workspace/tokenizer/merges.txt",
                    "--vocab-size",
                    "50257",
                    "--workers",
                    "8"
                ]
        },

        {
            "name": "Pretrain GPT",
            "type": "debugpy",
            "request": "launch",
            "module": "torch.distributed.run",
            "env": {
                "CUDA_VISIBLE_DEVICES": "5",
                "MASTER_ADDR": "localhost",
                "MASTER_PORT": "6001",
                "CUDA_DEVICE_MAX_CONNECTIONS": "1"
            },
            "args": [
                "--nnodes",
                "1",
                "--nproc_per_node",
                "1",
                "--rdzv-endpoint=0.0.0.0:29503",
                "pretrain_gpt.py",
                "--no-position-embedding",
                "--num-layers",
                "4",
                "--hidden-size",
                "2048",
                "--num-attention-heads",
                "4",
                "--seq-length",
                "2048",
                "--max-position-embeddings",
                "2048",
                "--vocab-file",
                "/workspace/tokenizer/vocab.json",
                "--merge-file",
                "/workspace/tokenizer/merges.txt",
                "--train-data-path",
                "/workspace/dataset/data/preprocessed_samples_text_document",
                "--save",
                "/workspace/checkpoints",
                "--save-interval",
                "10",
                "--lr",
                "0.0001",
                "--min-lr",
                "0.00001",
                "--bf16",
                "--tensor-model-parallel-size",
                "1",
                "--tensorboard-dir",
                "/workspace/data/tensorboards/Megatron-LM",
                "--train-iters",
                "20",
                "--micro-batch-size",
                "1",
                "--global-batch-size",
                "200",
                "--skip-train-iteration-range",
                "0-5"
            ],
            "console": "integratedTerminal",
            "justMyCode": true,
            "envFile": "${workspaceFolder}/.env"
        }
    ]
}